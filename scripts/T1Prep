#!/usr/bin/env bash
#
# PURPOSE: This script performs preprocessing steps on T1-weighted MRI images
#          to create segmentations and extract cortical surface. 
#
# USAGE: T1Prep [options] file1.nii file2.nii ...
#
# INPUT: T1-weighted MRI images in NIfTI format (.nii or .nii.gz).
#
# OUTPUT: Processed images and segmentation results in the specified output directory.
#
# FUNCTIONS: 
# - main: The main function that executes the preprocessing steps.
# - parse_args: Parses the command line arguments.
# - surface_estimation: Create cortical surfaces
# - process: Performs the preprocessing steps on each input file.
#
# ______________________________________________________________________
#
# Christian Gaser
# Structural Brain Mapping Group (https://neuro-jena.github.io)
# Departments of Neurology and Psychiatry
# Jena University Hospital
# ______________________________________________________________________

# ----------------------------------------------------------------------
# Global parameters
# ----------------------------------------------------------------------

# Defaults
version=0.2.3
script_dir=$(dirname "$0")

seed=0

# Load additional defaults
cfg="${script_dir}/../T1Prep_defaults.txt"

# Use some external functions
source "${script_dir}/utils.sh"
progress_bar="${script_dir}/progress_bar_multi.sh"


# ----------------------------------------------------------------------
# Run main
# ----------------------------------------------------------------------

main()
{
  check_python_cmd
  parse_args ${1+"$@"}
  check_python_cmd
  get_OS

  # Normalize and default numeric options to prevent integer comparison errors
  # multi: -2 (quiet), 0 (single), >0 (explicit parallel), -1 (auto)
  if ! [[ "${multi}" =~ ^-?[0-9]+$ ]]; then multi=-1; fi
  if ! [[ "${estimate_seg}" =~ ^[0-9]+$ ]]; then estimate_seg=1; fi
  if ! [[ "${estimate_surf}" =~ ^[0-9]+$ ]]; then estimate_surf=1; fi
  if ! [[ "${estimate_spherereg}" =~ ^[0-9]+$ ]]; then estimate_spherereg=1; fi
  if ! [[ "${save_pial_white}" =~ ^[0-9]+$ ]]; then save_pial_white=0; fi
  if ! [[ "${thickness_method}" =~ ^-?[0-9]+$ ]]; then thickness_method=3; fi
  if ! [[ "${debug}" =~ ^[0-9]+$ ]]; then debug=0; fi
  if ! [[ "${use_bids_naming}" =~ ^[0-9]+$ ]]; then use_bids_naming=0; fi
  if ! [[ "${min_memory}" =~ ^[0-9]+$ ]]; then min_memory=12; fi

  if [[ "$multi" -ne -2 ]]; then
    logo
    check_python_module venv
    check_python_module pip
    check_python_libraries
    if [ "$re_install" -eq 1 ]; then
      exit 0
    fi
  fi
  check_files "${#ARRAY[@]}"
  
  process "$@"

  exit 0
}


# ----------------------------------------------------------------------
# Check arguments and files
# ----------------------------------------------------------------------

parse_args()
{
  local optname optarg
  
  # Check default-file first and load it before any other options
  for ((i=1;i<=$#;i++)); do
      case "${!i}" in
          --default*)   cfg="${!((i+1))}"; i=$((i+1)) ;;
      esac
  done
  source "${cfg}"

  if [ $# -lt 1 ]; then
    logo
    help
    exit 1
  fi

  count=0
  while [ $# -gt 0 ]; do
    optname="${1%%=*}"
    optarg="${2:-}"

    case "$1" in
      --install | --re-install)
        re_install=1
        ;;
      --python)
        exit_if_empty "$optname" "$optarg"
        python=$optarg
        shift
        ;;
      --out*)
        exit_if_empty "$optname" "$optarg"
        outdir=$optarg
        shift
        ;;
      --pre-fwhm)
        exit_if_empty "$optname" "$optarg"
        pre_fwhm=$optarg
        shift
        ;;
      --downsample)
        exit_if_empty "$optname" "$optarg"
        downsample=$optarg
        shift
        ;;
      --median-filter)
        exit_if_empty "$optname" "$optarg"
        median_filter=$optarg
        shift
        ;;
      --vessel*)
        exit_if_empty "$optname" "$optarg"
        vessel=$optarg
        shift
        ;;
      --bin-dir| --bindir)
        exit_if_empty "$optname" "$optarg"
        bin_dir=$optarg
        shift
        ;;
      --no-overwrite*)
        exit_if_empty "$optname" "$optarg"
        no_overwrite=$optarg
        shift
        ;;
      --thickness-method)
        exit_if_empty "$optname" "$optarg"
        thickness_method=$optarg
        shift
        ;;
      --multi*)
        exit_if_empty "$optname" "$optarg"
        multi=$optarg
        shift
        ;;
      --seed)
        exit_if_empty "$optname" "$optarg"
        seed=$optarg
        shift
        ;;
      --atlas)
        exit_if_empty "$optname" "$optarg"
        atlas_vol=$optarg
        shift
        ;;
      --atlas-surf)
        exit_if_empty "$optname" "$optarg"
        atlas_surf=$optarg
        shift
        ;;
      --min-mem*)
        exit_if_empty "$optname" "$optarg"
        min_memory=$optarg
        shift
        ;;
      --gz)
        nii_ext='nii.gz'
        ;;
      --hemi*)
        save_hemi=1
        ;;
      --no-surf)
        estimate_surf=0
        ;;
      --no-seg*)
        estimate_seg=0
        ;;
      --no-sphere*)
        estimate_spherereg=0
        ;;
      --pial*)
        save_pial_white=1
        ;;
      --lesion*)
        save_lesions=1
        ;;
      --no-mwp* | --no-warped-seg*)
        save_mwp=0
        ;;
      --wp* | --warped-seg-nomod)
        save_wp=1
        ;;
      --rp* | --affine-seg)
        save_rp=1
        ;;
      --p* | --native-seg)
        save_p=1
        ;;
      --csf*)
        save_csf=1
        ;;
      --amap)
        use_amap=1
        ;;
      --bids)
        use_bids_naming=1
        nii_ext='nii.gz'
        ;;
      --no-correct-folding)
        correct_folding=0
        ;;
      --debug)
        debug=1
        ;;
      --fast)
        estimate_spherereg=0
        save_mwp=0
        atlas_vol=""
        atlas_surf=""
        ;;
      -h | --help | --h | -v | --version | -V)
        help
        exit 1
        ;;
      -*)
        echo "`basename $0`: ERROR: Unrecognized option \"$1\"" >&2
        exit 1
        ;;
      *)
        if [ ! -f "$1" ]; then
          if [ ! -L "$1" ]; then
            echo "${RED}File $1 was not found and will be skipped.${NC}" >&2
          fi
        else
          ARRAY[$count]=$1
          ((count++))
        fi
        ;;
    esac
    shift
  done

  if [[ "$estimate_seg" -eq 0 && "$estimate_surf" -eq 0 ]]; then
    echo "${RED}ERROR: Options "--no-surf" and "--no-seg" cannot be used together.${NC}" >&2
    exit 1
  fi

}

# ----------------------------------------------------------------------
# Surface estimation
# ----------------------------------------------------------------------

surface_estimation() 
{  
  local bname=$1
  local side=$2
  local mri_dir=$3
  local surf_dir=$4
  local estimate_spherereg=$5
  local multi=$6
  local nii_ext=$7
  
  # In order to prevent issues with white spaces in directory names it's easier
  # to change into the that directory and run all commands from here
  if [ "${mri_dir}" == "${surf_dir}" ]; then
    base_dir="${mri_dir}"
    mri_dir=""
    surf_dir=""
  else
    base_dir=$(dirname "${mri_dir}")
    mri_dir="mri"
    surf_dir="surf"
  fi
  cd "${base_dir}"

  # Guard local numeric variables for arithmetic checks
  if ! [[ "${estimate_spherereg}" =~ ^[0-9]+$ ]]; then estimate_spherereg=1; fi
  if ! [[ "${thickness_method}" =~ ^-?[0-9]+$ ]]; then thickness_method=3; fi
  if ! [[ "${save_pial_white}" =~ ^[0-9]+$ ]]; then save_pial_white=0; fi
  if ! [[ "${debug}" =~ ^[0-9]+$ ]]; then debug=0; fi
  if ! [[ "${multi}" =~ ^-?[0-9]+$ ]]; then multi=-1; fi

  # Freesurfer templates
  fshemi="${side/left/lh}"
  fshemi="${fshemi/right/rh}"
  Fsavg=${surf_templates_dir}/${fshemi}.central.freesurfer.gii
  Fsavgsphere=${surf_templates_dir}/${fshemi}.sphere.freesurfer.gii
  Fsavgatlas=${atlas_templates_dir}/${fshemi}

  # BIDS dependent parameters for coding hemispheres and column in Names.tsv
  if [[ $use_bids_naming -eq 1 ]]; then
    name_columns=3  # 3rd column in Names.tsv
    hemi="${side/left/L}"
    hemi="${hemi/right/R}"
  else
    name_columns=2  # 2nd column in Names.tsv
    hemi="${side/left/lh}"
    hemi="${hemi/right/rh}"
  fi

  # Create dynamic variables for filenames
  for code in "PBT_shape" "GMT_shape" "Hemi_volume" "mT1_volume" "PPM_volume" "GMT_volume" "Mid_surface" "Pial_surface" "WM_surface" "Sphere_surface" "Spherereg_surface" "Intensity_Mid" "Intensity_Pial" "Intensity_WM"; do
    pattern=$(get_pattern "$code" "$name_columns")
    value=$(substitute_pattern "$pattern" "$hemi" "" "")
    # Use eval to assign the result to a variable named after the code
    eval "${code}=\"\$value\""
  done

  # Change number of commands if spherical registration is disabled
  if [ "${estimate_spherereg}" -eq 1 ]; then
    ((end_count=6))
  else
    ((end_count=4))
  fi
  if [[ "${save_pial_white}" -eq 1 || "${thickness_method}" -eq 2 ]]; then
    ((end_count++))
  fi
  if [ "${debug}" -eq 0 ]; then
    verbose=""
  else 
    verbose=" -verbose "
  fi

  if [[ "$multi" -ne -2 && "$side" == "left" ]]; then
    show_bar=1
  else
    show_bar=0
  fi
  
  # This section of the script checks if a specific hemisphere file exists within a given directory.
  count=-1
  if [ -f "${mri_dir}/${Hemi_volume}" ]; then

    # Progress indication
    ((count++))
    if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Calculate thickness            "; fi
  
    # Executes the 'CAT_VolThicknessPbt' tool with various options:
    # - ${verbose} toggles verbose output.
    # - '-n-avgs 8' sets the number of averages for distance estimation.
    # - '-min-thickness' sets a minimum thickness threshold.
    # - '-fwhm' sets the FWHM for thickness smoothing.
    cmd="CAT_VolThicknessPbt ${verbose} -correct-voxelsize -0.75 -median-filter ${median_filter} -sharpen 0 -downsample ${downsample} -n-avgs 8 ${mri_dir}/${Hemi_volume} ${mri_dir}/${GMT_volume} ${mri_dir}/${PPM_volume}"
    run_cmd_log "${report_log}" "$cmd"
    
    # Exit if nothing was saved from 1st command
    if [[ ! -f "${mri_dir}/${PPM_volume}" ]]; then
      echo "${RED}ERROR: Surface estimation for $side hemisphere failed because an error occurred in CAT_VolThicknessPbt.${NC}" >&2
      return 1
    fi

    # Updates progress
    ((count++))
    if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Extract surface                "; fi
  
    # Executes the 'CAT_VolMarchingCubes' tool to generate a surface mesh from volumetric data:
    # - '-median-filter' applies a median filter a specified number of times to reduce artifacts.
    # - '-pre-fwhm' and '-post-fwhm' control pre and post smoothing.
    # - '-thresh' sets the isovalue for mesh generation.
    # - '-no-distopen' disables distance-based opening, a form of morphological operation.
    # - '-local-smoothing' applies additional local smoothing to the mesh.
    cmd="CAT_VolMarchingCubes ${verbose} -label ${mri_dir}/${Hemi_volume} -strength-gyrimask 0.1 -median-filter ${median_filter} -pre-fwhm ${pre_fwhm} -iter-laplacian 50 -thresh 0.5 ${mri_dir}/${PPM_volume} ${surf_dir}/${Mid_surface}"
    run_cmd_log "${report_log}" "$cmd"

    # Reduce surface mesh to smaller size:
    # - '-ratio' defines target triangle ratio in (0,1], e.g., 0.5 keeps ~50% of faces (default 0.25)
    # - '-aggr' defines aggressiveness of simplification (default 7)
    cmd="CAT_SurfReduce ${verbose} -aggr 7 -ratio 0.25 ${surf_dir}/${Mid_surface} ${surf_dir}/${Mid_surface}"
    run_cmd_log "${report_log}" "$cmd"

    # Updates progress
    ((count++))
    if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Map thickness values           "; fi

    # Executes 'CAT_Vol2Surf' to map volumetric data to a surface representation.
    # It uses a weighted average approach for mapping, ranging from -0.4..0.4 of the relative thickness using 5 steps
    cmd="CAT_Vol2Surf -weighted-avg -start -0.4 -steps 5 -end 0.4 ${surf_dir}/${Mid_surface} ${mri_dir}/${GMT_volume} ${surf_dir}/${PBT_shape}"
    run_cmd_log "${report_log}" "$cmd"
    
    # For thickness_method==3 we use the pure PBT-measure
    if [ "${thickness_method}" -eq 3 ]; then
      cp "${surf_dir}/${PBT_shape}" "${surf_dir}/${GMT_shape}"
    else
      cmd="CAT_SurfDistance ${verbose} -check_intersect -max 6.0 -mean -thickness ${surf_dir}/${PBT_shape} ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape}"
      run_cmd_log "${report_log}" "$cmd"
    fi

    # Updates progress
    ((count++))
    if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Refine central surface         "; fi

    # Obtain more accurate central surface by surface deformation to PPM image
    cmd="CAT_SurfDeform -remove_intersect -isovalue 0.5 -w1 0.1 -w2 0.1 -w3 1.0 -sigma 0.2 ${mri_dir}/${PPM_volume} ${surf_dir}/${Mid_surface} ${surf_dir}/${Mid_surface}"
    run_cmd_log "${report_log}" "$cmd"

    # Executes 'CAT_Surf2PialWhite' to estimate both pial and white matter surfaces.
    # - '-w1' sets the internal smoothness weight.
    # - '-w2' sets the gradient alignment weight.
    # - '-w3' sets the balloon force weight.
    # - '-sigma' sets the smoothing size for filtering the displacement field.
    # - '-iter' sets the number of iterations.
    # - '-isovalue' sets the isovalue for mesh generation.
    if [[ "${save_pial_white}" -eq 1 || "${thickness_method}" -eq 2 ]]; then
      # Updates progress
      ((count++))
      if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Estimate pial and white surface"; fi
      cmd=( "CAT_Surf2PialWhite ${verbose} -w1 0.05 -w2 0.05 -w3 0.05 -sigma 0.2 -iter 100 ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape} ${mri_dir}/${Hemi_volume} ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface}" )

      # Get central surface by averaging pial and white matter surface
      cmd+=( "CAT_SurfAverage -avg ${surf_dir}/${Mid_surface} ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface}" )
      run_cmd_log "${report_log}" "${cmd[@]}"
    fi
          
    # Optionally estimate thickness by using the mean distance (Tfs) between pial and white matter surface and limit to maximum of 6.0
    if [ "${thickness_method}" -eq 2 ]; then
      # Updates progress
      ((count++))
      if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Refine thickness               "; fi
      cmd="CAT_SurfDistance -max 6.0 -mean ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface} ${surf_dir}/${GMT_shape}"
      run_cmd_log "${report_log}" "$cmd"
    fi
    
    # Correct cortical thickness that is influenced by folding
    if [ "${correct_folding}" -eq 1 ]; then
      cmd="CAT_SurfCorrectThicknessFolding -max 6.0 ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape} ${surf_dir}/${GMT_shape}"
      run_cmd_log "${report_log}" "$cmd"
    fi

    # Map intensity values of bias-corrected image from central, pial, and white surface for debugging
    if [[ "${debug}" -eq 1 && -f "${mri_dir}/${mT1_volume}" ]]; then
      cmd=( "CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${Mid_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_Mid}" )
      if [ "${save_pial_white}" -eq 1 ]; then
        cmd+=( "CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${Pial_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_Pial}" )
        cmd+=( "CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${WM_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_WM}" )
      fi
      run_cmd_log "${report_log}" "${cmd[@]}"
    fi
  
    # If estimate_spherereg is enabled, additional steps for spherical inflation and estimate_spherereg are performed.
    if [ "${estimate_spherereg}" -eq 1 ]; then
      # Updates progress
      ((count++))
      if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Spherical inflation            "; fi
      # Inflates the surface to a sphere with additional areal smoothing.
      cmd="CAT_Surf2Sphere ${surf_dir}/${Mid_surface} ${surf_dir}/${Sphere_surface} 6"
      run_cmd_log "${report_log}" "$cmd"
  
      # Updates progress
      ((count++))
      if [ "$show_bar" -eq 1 ]; then ${progress_bar} 1 "" $count $end_count "Spherical registration         "; fi
      # Warps the surface to align with a standard sphere template, using specific mapping steps and averaging options.
      cmd="CAT_SurfWarp ${verbose} -steps 2 -avg -i ${surf_dir}/${Mid_surface} -is ${surf_dir}/${Sphere_surface} -t ${Fsavg} -ts ${Fsavgsphere} -ws ${surf_dir}/${Spherereg_surface}"
      run_cmd_log "${report_log}" "$cmd"
      
      # Resamples atlases to individual surface space
      code="ATLAS_label"
      pattern=$(get_pattern "$code" "$name_columns")
      # Create dynamic variables for filenames
      for atl in ${atlas_surf}; do
        value=$(substitute_pattern "$pattern" "$hemi" "" "" "$atl")
        # Use eval to assign the result to a variable named after the code
        eval "${code}=\"\$value\""

        cmd+=( "CAT_SurfResample -label ${Fsavg} ${Fsavgsphere} ${surf_dir}/${Spherereg_surface} NULL ${Fsavgatlas}.${atl}.annot ${surf_dir}/${ATLAS_label}" )
      done
      run_cmd_log "${report_log}" "${cmd[@]}"
    fi

    # remove temporary files if not debugging
    if [ "${debug}" -eq 0 ]; then
      for file in "${mri_dir}/${GMT_volume}" "${mri_dir}/${PPM_volume}"; do
        [ -f "${file}" ] && rm "${file}"
      done
    fi

    return 0

  else
    if [ "${estimate_seg}" -eq 0 ]; then
      echo "${RED}ERROR: Could not find ${mri_dir}/${Hemi_volume}.${NC}" >&2
    else
      echo "${RED}ERROR: Segmentation module (segment) failed.${NC}" >&2
    fi
    return 1
  fi
}

# ----------------------------------------------------------------------
# Process data
# ----------------------------------------------------------------------

process()
{
  errors=0
  SIZE_OF_ARRAY="${#ARRAY[@]}"
  if ! [[ "${multi}" =~ ^-?[0-9]+$ ]]; then multi=-1; fi
  if [[ "$SIZE_OF_ARRAY" -lt 2 && "$multi" -ne -2 ]]; then
    multi=0
  fi
  
  # Call T1Prep script recursively with different "--multi" arguments in case that
  # "--multi" is defined
  if [[ "$multi" -ne 0 && "$multi" -gt -2 ]]; then

    # Filter arguments before recursion
    filtered_args=($(filter_arguments "$@")) # Use an array to handle filtered arguments

    # Get number of processes (NUM_JOBS) for defined memory limit
    # Ensure min_memory sane before calculating
    if ! [[ "${min_memory}" =~ ^[0-9]+$ ]]; then min_memory=12; fi
    get_no_processes ${min_memory}
    
    # If multi is defined and lower than available processes w.r.t. memory limit,
    # then use this lower value
    if [[ "$multi" -gt 0 && "$NUM_JOBS" -gt "$multi" ]]; then
      arg_parallelize="-p ${multi}"
    else
      arg_parallelize="-p ${NUM_JOBS}"
    fi
    
    # Call parallelize with filtered arguments and use memory limit per process
    # and a small delay of 5s between the jobs to avoid simultaneous peak memory usage
    cmd=(
      "${script_dir}/parallelize"
      -l "/tmp"
      -d 5
      "${arg_parallelize}"
      -c "$(printf '"%q "' "$0" ${filtered_args[@]} --no-surf --hemisphere --multi -2)"
      "${ARRAY[@]}"
    )
    
    # Execute the command using eval
    if [ "${estimate_seg}" -eq 1 ]; then
      echo "${BOLD}Volume Segmentation${NC}"
      eval "${cmd[@]}"
      status=$?
    fi

    # Call parallelize with filtered arguments
    # Define number of processes, otherwise estimate it automatically 
    if ! [[ "${multi}" =~ ^-?[0-9]+$ ]]; then multi=-1; fi
    if [ "$multi" -gt 0 ]; then
      arg_parallelize="-p ${multi}"
    else
      arg_parallelize="-p 0.5"
    fi
    cmd=(
      "${script_dir}/parallelize"
      -l "/tmp"
      "${arg_parallelize}"
      -c "$(printf '"%q "' "$0" ${filtered_args[@]} --no-seg --multi -2)"
      "${ARRAY[@]}"
    )
    
    # Execute the command using eval
    if [ "${estimate_surf}" -eq 1 ]; then
      echo "${BOLD}Surface Estimation${NC}"
      eval "${cmd[@]}"
      status=$?
    fi
    
    exit $status
  fi

  # Don't use colored text in parallelization (for clearer log-file)
  if [[ "$multi" -eq -2 ]]; then
    UNDERLINE=""
    BOLD=""
    NC=""
    CYAN=""
    PINK=""
    RED=""
    YELLOW=""
    BLUE=""
    WHITE=""
    GREEN=""
    BLACK=""
  fi
  
  # Later add string that indicates use of AMAP
  if [[ "${use_amap}" -eq 1 ]]; then
    amap_string=""
  else
    amap_string="-no-amap"
  fi
  
  i=0
  j=0
  while [ "$i" -lt "$SIZE_OF_ARRAY" ]; do

    # Check whether absolute or relative names were given
    if [ ! -f "${ARRAY[$i]}" ]; then
      if [ -f "${pwd}/${ARRAY[$i]}" ]; then
        FILE="${pwd}/${ARRAY[$i]}"
      fi
    else
      FILE="${ARRAY[$i]}"
    fi

  # Do not mangle spaces; always quote variables instead

    # Check whether processed files exist if no-overwrite flag is used
    if [ -n "${no_overwrite}" ]; then
      
      get_output_folder "$FILE"
      
      if [ "${use_bids_naming}" -eq 1 ]; then  
        processed=$(ls "${outdir0}/${bname}"*"/${no_overwrite}"* 2>/dev/null)
      else
        processed=$(ls "${outdir0}/${no_overwrite}${bname}"* 2>/dev/null)
      fi
    fi
    
    if [ -z "${processed}" ]; then
      ARRAY2[$j]="$FILE"
      ((j++))
    else
      echo Skip processing of "${FILE}"
    fi
    ((i++))
  done
  
  
  i=0
  SIZE_OF_ARRAY="${#ARRAY2[@]}"
  
  # Exit if no files could be found for processing
  if [ "$SIZE_OF_ARRAY" -eq 0 ]; then
    exit 0
  fi

  # Set overall starting time
  start0=$(date +%s)

  # Use defined environment
  source ${T1prep_env}/bin/activate

  while [ "$i" -lt "$SIZE_OF_ARRAY" ]; do
    
    # Set starting time
    start=$(date +%s)

    FILE="${ARRAY2[$i]}"

    get_output_folder "$FILE"

    # Check again whether processed files exist if no-overwrite flag is used
    if [ -n "${no_overwrite}" ]; then
      if [ "${use_bids_naming}" -eq 1 ]; then  
        processed=$(ls "${outdir0}/${no_overwrite}${bname}"* 2>/dev/null)
      else
        processed=$(ls "${outdir0}/${bname}"*"${no_overwrite}"* 2>/dev/null)
      fi

      # Check if $processed is empty
      if [ -n "$processed" ]; then
        echo Skip processing of "${FILE}"
        break  # Skip to the next iteration of the loop
      fi
    fi
    
    # Get output folders for surfaces and volumes
    if [[ "${use_bids_naming}" -eq 1 || "${use_subfolder}" -eq 0 ]]; then  
      mri_dir=${outdir0}
      surf_dir=${outdir0}
      report_dir=${outdir0}
      label_dir=${outdir0}
    else
      mri_dir=${outdir0}/mri
      surf_dir=${outdir0}/surf
      report_dir=${outdir0}/report
      label_dir=${outdir0}/label
    fi
              
    # Create output folders    
    # Create output folders (quote each to support spaces in paths)
    if [ "${estimate_surf}" -eq 1 ]; then
      mkdir -p "${mri_dir}" "${surf_dir}" "${report_dir}" "${label_dir}"
    else
      mkdir -p "${mri_dir}" "${report_dir}" "${label_dir}"
    fi
    
    # Get filename for log file
    code="Log_file"
    if [[ $use_bids_naming -eq 1 ]]; then
      name_columns=3  # 3rd column in Names.tsv
    else
      name_columns=2  # 2nd column in Names.tsv
    fi
    pattern=$(get_pattern "$code" "$name_columns")
    # Create dynamic variables for filenames
    value=$(substitute_pattern "$pattern" "" "" "" "")
    # Use eval to assign the result to a variable named after the code
    eval "${code}=\"\$value\""

    # Save all output in log-file
    report_log=${report_dir}/${Log_file}
    echo "T1Prep version ${version}" > "${report_log}"
    date >> "${report_log}"
    echo "${os_type}" >> "${report_log}"
    cuda=$(${python} -c "import torch; print(torch.cuda.is_available())" 2>/dev/null)
    if [ "${cuda}" == "True" ]; then
      echo "Use Cuda in Python" >> "${report_log}"
    else
      echo "Use CPU in Python" >> "${report_log}"
    fi
    
    # Print progress and filename
    j=$(expr $i + 1)
    if [ "${multi}" -ne -2 ]; then
      echo "${BOLD}----------------------------------------------------------${NC}"
      if [ "${SIZE_OF_ARRAY}" -gt 1 ]; then
        echo "${GREEN}${j}/${SIZE_OF_ARRAY} ${BOLD}Processing ${FILE}${NC}"
      else
        echo "${BOLD}Processing ${FILE}${NC}"
      fi
    fi

    input="${FILE}"
    
    # 1. Call deepmriprep segmentation 
    # ----------------------------------------------------------------------
    # Check for outputs from previous step
    if [ -f "${input}" ]; then

      # Ensure Python can import the package from src and run the module entry
      export PYTHONPATH="${src_dir}:${PYTHONPATH}"
      # Initialize command string with the Python module call so relative imports work
      cmd="${python} ${src_dir}/segment.py"
      
      # Append options conditionally
      [ "${use_amap}" -eq 1 ] && cmd+=" --amap --amapdir ${bin_dir}"
      [ "${save_mwp}" -eq 1 ] && cmd+=" --mwp"
      [ "${save_wp}" -eq 1 ] && cmd+=" --wp"
      [ "${save_rp}" -eq 1 ] && cmd+=" --rp"
      [ "${save_p}" -eq 1 ] && cmd+=" --p"
      [ "${nii_ext}" == "nii.gz" ] && cmd+=" --gz"
      [ "${save_lesions}" -eq 1 ] && cmd+=" --lesions --amapdir ${bin_dir}"
      [ "${use_bids_naming}" -eq 1 ] && cmd+=" --bids"
      [ "${multi}" -ne -2 ] && cmd+=" --verbose"
      [ "${debug}" -eq 1 ] && cmd+=" --debug"
      [ "${estimate_surf}" -eq 1 ] || [ "${save_hemi}" -eq 1 ] && cmd+=" --surf"
      [ "${save_csf}" -eq 1 ] && cmd+=" --csf"

      cmd+=" --seed ${seed} --vessel \"${vessel}\" --label_dir \"${label_dir}\""
      cmd+=" --input \"${input}\" --mri_dir \"${mri_dir}\""
      cmd+=" --report_dir \"${report_dir}\" --atlas \"${atlas_vol}\""
      
      # Execute the command and capture exit code
      if [ "${estimate_seg}" -eq 1 ]; then
        echo "${cmd}" >> "${report_log}" 
        if [[ "$multi" -ne -2 ]]; then
          eval "${cmd}"
        else
          eval "${cmd}" 2>&1 | tee -a "${report_log}"
        fi
        seg_status=$?
      else
        seg_status=0
      fi

      if [ "$seg_status" -ne 0 ]; then
        if [[ "$multi" -ne -2 ]]; then
          # Use 1/1 so the single job bar renders without relying on end_count
          ${script_dir}/progress_bar_multi.sh 1 "" 1 1 "Segmentation failed" 40 1
        fi
        ((i++))
        ((errors++))
        echo "Error in ${input}"
        continue
      fi
  
    else
      echo "${RED}ERROR: ${input} could not be found.${NC}" >&2
      ((i++))
      ((errors++))
      continue
    fi
    
    # Optionally extract surface
    if [ "${estimate_surf}" -eq 1 ]; then

      # Set starting time
      start_surf=$(date +%s)
        
      # 2. Estimate thickness and percentage position maps for each hemisphere
      # and extract cortical surface and call it as background process to
      # allow parallelization
      # ----------------------------------------------------------------------
      # Check for outputs from previous step
      pids=()
      for side in left right; do
        surface_estimation $bname $side "${mri_dir}" "${surf_dir}" $estimate_spherereg $multi "${nii_ext}" &
        pids+=("$!")
      done

      surf_status=0
      for pid in "${pids[@]}"; do
        wait "$pid" || surf_status=1
      done

      if [ "$surf_status" -ne 0 ]; then
        if [[ "$multi" -ne -2 ]]; then
          # Use 1/1 so the single job bar renders without relying on end_count
          ${script_dir}/progress_bar_multi.sh 1 "" 1 1 "Surface estimation failed" 40 1
        fi
        ((errors++))
        echo "Error in ${bname}"
      fi

      end_surf=$(date +%s)
      runtime=$((end_surf - start_surf))
      echo "" >> "${report_log}"
      echo "Execution time surface pipeline: ${runtime}s" >> "${report_log}"
      
    fi # estimate_surf

    # Print execution time per data set
    end=$(date +%s)
    runtime=$((end - start))
    hours=$(($runtime / 3600))
    min=$((($runtime / 60) % 60))
    s=$(($runtime % 60))
    overall="Finished after "
    if [ $hours -gt 0 ]; then overall+="${hours}hrs "; fi
    if [ $min -gt 0 ]; then overall+="${min}min "; fi
    overall+="${s}s"

    if [ "${estimate_surf}" -eq 1 ]; then
      echo "${overall}" >> "${report_log}"
    fi
    
    if [[ "$multi" -ne -2 ]]; then
      echo "${GREEN}----------------------------------------------------------                                ${NC}"
      echo "${GREEN}${overall}${NC}"
    fi
      
    ((i++))
  done
  
  # Print overall execution time for more than one data set
  if [ "$SIZE_OF_ARRAY" -gt 1 ]; then
    end0=`date +%s`
    runtime=$((end0-start0))
    runtime="T1Prep finished after $(($runtime / 3600))hrs $((($runtime / 60) % 60))min $(($runtime % 60))s"
    echo "${GREEN}${runtime}${NC}"  
  fi
  
  exit $errors

}

# ----------------------------------------------------------------------
# Help
# ----------------------------------------------------------------------

help() {
cat << EOM
${BOLD}${BLUE}T1Prep Computational Anatomy Pipeline (aka PyCAT)
-----------------------------------------------------------------------------------${NC}

${BOLD}USAGE:${NC}
  ${GREEN}T1Prep [options] <filename(s)>${NC}

${BOLD}Tool Overview:${NC}
T1Prep is a pipeline that preprocesses T1-weighted MRI data and supports segmentation 
and cortical surface reconstruction. It provides a complete set of tools for efficiently 
processing structural MRI scans.

T1Prep partially integrates DeepMriPrep, which uses deep learning (DL) techniques to 
mimic functionality of CAT12 for processing structural MRIs. DeepMriPrep is used for 
skull-stripping, segmentation and nonlinear spatial registration.

An alternative approach uses DeepMriPrep for bias field correction, lesion detection, 
and also serves as an initial estimate for the subsequent AMAP segmentation from CAT12. 

Cortical surface reconstruction and thickness estimation are performed using Cortex 
Analysis Tools for Surface, a core component of the CAT12 toolbox.

It is designed for both single-subject and batch processing, with optional parallelization
and flexible output naming conventions. The naming patterns are compatible with both 
CAT12 folder structures and the BIDS derivatives standard.

${BOLD}Output Folder Behaviour:${NC}
The location and structure of the output folders depend on:

1. Whether the input data follow the BIDS structure
  If the upper-level folder of the NIfTI file is named 'anat', the script assumes 
  a BIDS dataset. Output will then be written into a BIDS-compatible derivatives folder:

  '<dataset-root>/derivatives/T1Prep-v<version>/<sub-XXX>/<ses-YYY>/anat/'
  where sub-XXX and ses-YYY are automatically detected from the path.

2. Non-BIDS datasets

  If the upper-level folder is not anat, results are written into subfolders similar 
  to CAT12 output inside the specified output directory (or the current working 
  directory if none is specified).

3. Folder naming conventions

  By default, CAT12-style names are used.
  If --bids is set, BIDS-compatible names are used instead.
  The mapping between internal processing outputs and their filenames for each 
  convention is stored in Names.tsv.

4. Custom output folder

  You can specify --out-dir <DIR> to override the default location.
  If --bids is set, the BIDS substructure will still be appended inside <DIR>.
  
${BOLD}Naming conventions:${NC}
CAT12 style (default): Uses legacy names for files and subfolders (mri, surf, etc.).

BIDS style (--bids): Uses BIDS derivatives naming rules for filenames and metadata.

The mapping between internal processing steps and filenames for both conventions 
is defined in Names.tsv. This file can be edited to customize output naming.
  
${BOLD}Options:${NC}
${BOLD}${GREEN}General Options:${NC}
  --defaults <FILE>           
      Specify an alternative defaults file to override built-in settings.

  --install                   
      Install all required Python libraries.

  --re-install                
      Remove the existing installation and re-install all required Python libraries.

  --python <FILE>             
      Path to the Python interpreter to use (default: $python).

  --multi <NUMBER>            
      Set the maximum number of parallel jobs. Use '-1' to automatically 
      detect and use all available CPU cores (default: $multi).  
      If you specify a value here and it is lower than the number of jobs 
      calculated based on --min-memory, your specified value will be used.

  --min-memory <NUMBER>
      Set the minimum amount of memory (in GB) to reserve for each parallel
      job (default: $min_memory GB). This value is used to estimate the
      maximum number of jobs that can run in parallel without exceeding
      available system memory. Increase this value if your system runs
      low on memory or becomes unresponsive during parallelization.

  --seed <NUMBER>
      Set the random seed for deterministic processing (default: $seed).

  --debug
      Enable verbose output, retain all temporary files, and save additional
      debugging information for inspection.

${BOLD}${GREEN}Save Options:${NC}
  --out-dir <DIR>             
      Set the base output directory (relative or absolute).  
      Default: the current working directory.

      Output folder structure depends on the input dataset type:
        • BIDS datasets (if the upper-level folder of the input files is 'anat'):
            Results are placed in a BIDS-compatible derivatives folder:
              <dataset-root>/derivatives/T1Prep-v<version>/<sub-XXX>/<ses-YYY>/anat/
            Subject ('sub-XXX') and session ('ses-YYY') are auto-detected.
        • Non-BIDS datasets:
            Results are placed in subfolders similar to CAT12 output
            (e.g., 'mri/', 'surf/', 'report/', 'label') inside the specified output directory.

      If '--bids' is set, the BIDS derivatives substructure will always be used
      inside '<DIR>'.

  --bids                      
      Use BIDS derivatives naming conventions for all output files and folders
      instead of the default CAT12 style.
      
      Naming behaviour:
        • CAT12 style (default): Uses legacy folder and file names
          (e.g., 'mri/mwp1sub-01.nii', 'surf/lh.thickness.sub-01').
        • BIDS style: Uses standardized derivatives names, including subject/session
          identifiers, modality, and processing steps
          (e.g., 'sub-01_ses-1_space-MNI152NLin2009cAsym-nonlinear-modulated_label-WM_probseg.gz',
          'sub-01_ses-1_hemi-L_thickness.shape.gii').

      The complete mapping between internal outputs and both naming conventions
      is stored in 'Names.tsv' and can be customized.

      Examples:
        Input: /data/study/sub-01/ses-1/anat/sub-01_ses-1_T1w.nii.gz
        Default output (no --out-dir):
            /data/study/derivatives/T1Prep-v${version}/sub-01/ses-1/anat/
        With --out-dir /results:
            /results/derivatives/T1Prep-v${version}/sub-01/ses-1/anat/

        Input: /data/T1_images/subject01.nii.gz
        Default output (no --out-dir):
            /data/T1_images/mri/
        With --out-dir /results:
            /results/mri/

  --no-overwrite <STRING>     
      Prevent overwriting existing results by checking for the given filename pattern.

  --gz                        
      Save images in compressed NIfTI format (*.nii.gz).

  --no-surf                   
      Skip surface and cortical thickness estimation.

  --no-seg                    
      Skip tissue segmentation processing.

  --no-sphere-reg             
      Skip spherical surface registration.

  --no-mwp                    
      Skip estimation of modulated and warped segmentations.

  --pial-white                
      Additionally estimate pial and white matter surfaces during surface processing.

  --hemisphere                
      Additionally save hemispheric partitions of the segmentation.

  --wp                        
      Additionally save warped segmentations.

  --rp                        
      Additionally save affine-registered segmentations.

  --p                         
      Additionally save native-space segmentations.

  --csf                       
      Additionally save CSF segmentations (default: only GM/WM are saved).
      This works currently only for native-space and affine-registered segmentations.

  --lesions                   
      Additionally save WMH lesion segmentations.
      This works currently only for native-space and affine-registered segmentations.

  --atlas                     
      Specify a volumetric atlas list in the format 
      "'suit','cobra'" (default: $atlas_vol).

  --atlas-surf                
      Specify a surface atlas list in the format 
      "'aparc_DK40.freesurfer','aparc_a2009s.freesurfer'" 
      (default: $atlas_surf).

${BOLD}${GREEN}Expert Options:${NC}
  --amap                      
      Use DeepMRIPrep segmentation only as initialization, followed by AMAP segmentation.

  --thickness-method <NUMBER> 
      Set the cortical thickness estimation method (default: $thickness_method):  
        1 = Tfs-distance (FreeSurfer) for PBT-based measure  
        2 = Tfs-distance (FreeSurfer) based on pial-to-white surface distance  
        3 = Pure PBT-based approach

  --no-correct-folding        
      Disable cortical thickness correction for folding effects.

  --pre-fwhm <NUMBER>         
      Set the pre-smoothing kernel size (FWHM) for CAT_VolMarchingCubes 
      (default: $pre_fwhm).

  --vessel <NUMBER>           
      Set the initial white matter threshold for vessel removal:  
        0.2 = mild cleanup  
        0.4 = medium cleanup  
        0.6 = strong cleanup  
        0   = disable vessel removal  
      (default: $vessel)

  --median-filter <NUMBER>    
      Apply the specified number of median filter passes to reduce topology artifacts
      (default: $median_filter).

  --fast                      
      Skip spherical registration, atlas estimation, and warped segmentation steps.
  
${BOLD}${GREEN}Examples:${NC}
${BLUE}${root_dir}/T1Prep --out-dir test_folder sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Generate segmentation and 
  surface maps, saving the results in the 'test_folder' directory.

${BLUE}${root_dir}/T1Prep --no-surf sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii', but skip surface creation. 
  Only segmentation maps are generated and saved in the same directory as the input files.

${BLUE}${root_dir}/T1Prep --python python3.9 --no-overwrite "surf/lh.thickness." sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii' and use python3.9. Skip processing
  for files where 'surf/lh.thickness.*' already exists, and save new results in the same
  directory as the input files.

${BLUE}${root_dir}/T1Prep --lesions --no-sphere-reg sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Skip processing of spherical
  registration, but additionally save lesion map (named p7sTRIO*.nii) in native space.
   
${BLUE}${root_dir}/T1Prep --no-amap sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii' and use DeppMriPrep instead of AMAP
  segmentation.

${BLUE}${root_dir}/T1Prep --multi 8 --p --csf --atlas "'neuromorphometrics', 'suit'" sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Additionally save segmentations 
  in native space, including CSF segmentation and estimate ROI volumes for the defined atlases.
  The processing pipeline involves two stages 
  of parallelization:
  
  1. Segmentation (Python-based): Runs best with at least 12GB of memory per process. 
     The number of processes is automatically estimated based on available memory to 
     optimize resource usage. If you notice system overload due to peak memory usage
     you can set a higher minimum memory limit using the "--min-memory" flag.

  2. Surface Extraction: This stage does not require significant memory and is 
     distributed across all available processors or limited to the defined number of
     processes using the "--multi" flag.

  If "--multi" is set to a specific number (e.g., 8), the system still estimates memory-based 
  constraints for segmentation parallelization. However, the specified number of processes 
  (e.g., 8) will be used for surface extraction, ensuring efficient parallelization across 
  the two stages. The default setting is -1, which automatically estimates the number of
  available processors.
    
${BOLD}Purpose:${NC}
  This script facilitates the analysis of T1-weighted brain images by providing tools for 
  segmentation, surface mapping, and more.

${BOLD}Input:${NC}
  Accepts NIfTI files as input (extension nii/nii.gz).

${BOLD}Output:${NC}
  Produces segmented images and surface extractions.

${BOLD}Used Functions:${NC}
  CAT_VolAmap
  CAT_VolSanlm
  CAT_VolThicknessPbt
  CAT_VolMarchingCubes
  CAT_Vol2Surf
  CAT_SurfAverage
  CAT_Surf2PialWhite
  CAT_SurfDistance
  CAT_SurfWarp
  CAT_Surf2Sphere
  CAT_SurfDeform
  CAT_SurfCorrectThicknessFolding
  CAT_SurfReduce
  CAT_SurfResample
  segment.py
  progress_bar_multi.sh
  parallelize

${BOLD}Author:${NC}
  Christian Gaser (christian.gaser@uni-jena.de)

EOM

check_python_cmd
get_OS

# Check whether local Python environment exists
if [ ! -d "${T1prep_env}" ]; then

  # Prompt the user with a Y/N question
  echo "${RED}${BOLD}Local Python environment "${T1prep_env}" not found.${NC}"
  read -p "Do you want to install required Python libraries? (Y/N)" response
  
  # Check if the user's answer is 'Y'
  case "$response" in
    [Yy]*)
      check_python_module venv
      check_python_module pip
      check_python_libraries
      ;;
  esac
fi

}

# ----------------------------------------------------------------------
# call main program
# ----------------------------------------------------------------------

main "${@}"
  