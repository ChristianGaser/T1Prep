#! /bin/bash
#
# PURPOSE: This script performs preprocessing steps on T1-weighted MRI images
#          to create segmentations and extract cortical surface. 
#
# USAGE: T1Prep [options] file1.nii file2.nii ...
#
# INPUT: T1-weighted MRI images in NIfTI format (.nii or .nii.gz).
#
# OUTPUT: Processed images and segmentation results in the specified output directory.
#
# FUNCTIONS: 
# - main: The main function that executes the preprocessing steps.
# - parse_args: Parses the command line arguments.
# - exit_if_empty: Checks if a command line argument is empty and exits with an error message if it is.
# - check_python_cmd: Checks if the Python command is available.
# - check_files: Checks if the input files exist.
# - check_python: Checks if the specified Python command is available.
# - check_python_module: Checks for python modules.
# - check_python_libraries: Checks for python libraries.
# - get_OS: Identifies operations system and folder of binaries.
# - surface_estimation: Create cortical surfaces
# - get_pattern: Get the pattern from the desired column in namefile
# - substitute_pattern: Substitute variables in the pattern
# - process: Performs the preprocessing steps on each input file.
#
# ______________________________________________________________________
#
# Christian Gaser
# Structural Brain Mapping Group (https://neuro-jena.github.io)
# Departments of Neurology and Psychiatry
# Jena University Hospital
# ______________________________________________________________________

# ----------------------------------------------------------------------
# global parameters
# ----------------------------------------------------------------------

# defaults
script_dir=$(dirname "$0")
root_dir=$(dirname $script_dir)
name_file=${root_dir}/Names.tsv
surf_templates_dir=${root_dir}/data/templates_surfaces_32k
T1prep_env=${root_dir}/env
src_dir=${root_dir}/src
cfg="${script_dir}/../T1Prep_defaults.txt"

# Use some external functions
source "${script_dir}/utils.sh"
source "${script_dir}/progress_bar.sh"


# ----------------------------------------------------------------------
# run main
# ----------------------------------------------------------------------

main()
{
  check_python_cmd  
  parse_args ${1+"$@"}
  if [[ "$multi" -ne -2 ]]; then
    logo
    check_python
    check_python_module venv
    check_python_module pip
    check_python_libraries    
  fi

  check_files
  get_OS
  
  process "$@"

  exit 0
}


# ----------------------------------------------------------------------
# check arguments and files
# ----------------------------------------------------------------------

parse_args()
{
  local optname optarg
  
  if [ $# -lt 1 ]; then
    logo
    help
    exit 1
  fi

  # Check default-file first and load it before any other options
  for ((i=1;i<=$#;i++)); do
      case "${!i}" in
          --default*)   cfg="${!((i+1))}"; i=$((i+1)) ;;
      esac
  done
  source "${cfg}"

  count=0
  while [ $# -gt 0 ]; do
    optname="${1%%=*}"
    optarg="${2:-}"

    case "$1" in
      --install | --re-install)
        re_install=1
        ;;
      --python)
        exit_if_empty "$optname" "$optarg"
        python=$optarg
        shift
        ;;
      --out*)
        exit_if_empty "$optname" "$optarg"
        outdir=$optarg
        shift
        ;;
      --pre-fwhm)
        exit_if_empty "$optname" "$optarg"
        pre_fwhm=$optarg
        shift
        ;;
      --thickness-fwhm)
        exit_if_empty "$optname" "$optarg"
        thickness_fwhm=$optarg
        shift
        ;;
      --downsample)
        exit_if_empty "$optname" "$optarg"
        downsample=$optarg
        shift
        ;;
      --sharpen*)
        exit_if_empty "$optname" "$optarg"
        sharpening=$optarg
        shift
        ;;
      --median-filter)
        exit_if_empty "$optname" "$optarg"
        median_filter=$optarg
        shift
        ;;
      --vessel*)
        exit_if_empty "$optname" "$optarg"
        vessel=$optarg
        shift
        ;;
      --bin-dir| --bindir)
        exit_if_empty "$optname" "$optarg"
        bin_dir=$optarg
        shift
        ;;
      --no-overwrite*)
        exit_if_empty "$optname" "$optarg"
        no_overwrite=$optarg
        shift
        ;;
      --thickness-method)
        exit_if_empty "$optname" "$optarg"
        thickness_method=$optarg
        shift
        ;;
      --multi*)
        exit_if_empty "$optname" "$optarg"
        multi=$optarg
        shift
        ;;
      --atlas*)
        exit_if_empty "$optname" "$optarg"
        atlas=$optarg
        shift
        ;;
      --min-mem*)
        exit_if_empty "$optname" "$optarg"
        min_memory=$optarg
        shift
        ;;
      --gz)
        nii_ext='nii.gz'
        ;;
      --hemi*)
        save_hemi=1
        ;;
      --no-surf)
        save_surf=0
        ;;
      --no-seg*)
        estimate_seg=0
        ;;
      --no-sphere*)
        estimate_spherereg=0
        ;;
      --pial*)
        save_pial_white=1
        ;;
      --lesion*)
        save_lesions=1
        ;;
      --no-mwp* | --no-warped-seg*)
        save_mwp=0
        ;;
      --wp* | --warped-seg-nomod)
        save_wp=1
        ;;
      --rp* | --affine-seg)
        save_rp=1
        ;;
      --p* | --native-seg)
        save_p=1
        ;;
      --csf*)
        save_csf=1
        ;;
      --no-amap)
        use_amap=0
        ;;
      --bids)
        use_bids_naming=1
        nii_ext='nii.gz'
        ;;
      --no-correct-folding)
        correct_folding=0
        ;;
      --debug)
        debug=1
        ;;
      -h | --help | --h | -v | --version | -V)
        help
        exit 1
        ;;
      -*)
        echo "`basename $0`: ERROR: Unrecognized option \"$1\"" >&2
        exit 1
        ;;
      *)
        if [ ! -f "$1" ]; then
          if [ ! -L "$1" ]; then
            echo "${RED}File $1 was not found and will be skipped.${NC}" >&2
          fi
        else
          ARRAY[$count]=$1
          ((count++))
        fi
        ;;
    esac
    shift
  done

  if [[ "$estimate_seg" -eq 0 && "$save_surf" -eq 0 ]]; then
    echo "${RED}ERROR: Options "--no-surf" and "--no-seg" cannot be used together.${NC}" >&2
    exit 1
  fi

}

# ----------------------------------------------------------------------
# logo
# ----------------------------------------------------------------------

logo()
{
echo $BLUE
cat <<__EOM__

████████╗ ██╗ ██████╗ ██████╗ ███████╗██████╗
╚══██╔══╝███║ ██╔══██╗██╔══██╗██╔════╝██╔══██╗
   ██║    ██║ █████╔╝║██████╔╝█████╗  ██████╔╝
   ██║    ██║ ██╔═══╝ ██╔══██╗██╔══╝  ██╔═══╝ 
   ██║    ██║ ██║     ██║  ██║███████╗██║   
   ╚═╝    ╚═╝ ╚═╝     ╚═╝  ╚═ ╚══════╝╚═╝   

__EOM__
echo $NC
}

# ----------------------------------------------------------------------
# check for python version
# ----------------------------------------------------------------------

check_python_cmd()
{
  if [ -z "${python}" ]; then
    if command -v python3 &>/dev/null; then
      python="python3"
    elif command -v python &>/dev/null; then
      python="python"
    else
      echo "${RED}python or python3 not found. Please use '--python' flag to define Python command and/or install Python${NC}" 2>&1
      exit 1
    fi
  fi
}

# ----------------------------------------------------------------------
# check files
# ----------------------------------------------------------------------

check_files()
{
  SIZE_OF_ARRAY="${#ARRAY[@]}"
  if [ "$SIZE_OF_ARRAY" -eq 0 ]; then
    echo "${RED}ERROR: No files given!${NC}" >&2
    help
    exit 1
  fi

  i=0
  while [ "$i" -lt "$SIZE_OF_ARRAY" ]; do
    if [[ ! "${ARRAY[$i]}" =~ \.nii(\.gz)?$ ]]; then
      echo "${RED}ERROR: File ${ARRAY[$i]} is not a valid NIfTI file${NC}" >&2
      help
      exit 1
    fi
    ((i++))
  done

}

# ----------------------------------------------------------------------
# check for python
# ----------------------------------------------------------------------

check_python()
{
  if ! command -v "${python}" &>/dev/null; then
    echo "${RED}ERROR: $python not found${NC}" >&2
    exit 1
  fi
}

# ----------------------------------------------------------------------
# check for python modules (e.g. pip)
# ----------------------------------------------------------------------

check_python_module() {
    ${python} -c "import $1" 2>/dev/null
    if [ $? -ne 0 ]; then
        echo "Error: Python module '$1' is not installed."
        echo "On Linux use 'apt install $(basename "$python")-"$1"'"
        exit 1
    fi
}

# ----------------------------------------------------------------------
# check for python libraries
# ----------------------------------------------------------------------

check_python_libraries()
{
  # Remove T1pre-env if reinstallation is selected
  if [[ -d "${T1prep_env}" && "${re_install}" -eq 1 ]]; then
    rm -r "${T1prep_env}"
  fi

  if [ ! -d ${T1prep_env} ]; then
    $python -m venv ${T1prep_env}
    install_deepmriprep
  fi
  source ${T1prep_env}/bin/activate
  
  $python -c "import deepmriprep" &>/dev/null
  if [ $? -gt 0 ]; then
    install_deepmriprep
  fi
}

# ----------------------------------------------------------------------
# install deepmriprep
# ----------------------------------------------------------------------

install_deepmriprep()
{
  echo "Install deepmriprep"
  $python -m venv ${T1prep_env}
  source ${T1prep_env}/bin/activate
  $python -m pip install -U pip
  $python -m pip install -r ${root_dir}/requirements.txt
  
  $python -c "import deepmriprep" &>/dev/null
  if [ $? -gt 0 ]; then
    echo "${RED}ERROR: Installation of deepmriprep not successful. 
      Please install it manually${NC}" >&2
    exit 1
  fi
  
  # Allow executable on MacOS
  case "$os_type" in
    Darwin*)  
      find MacOS -name "${bin_dir}/CAT*" -exec xattr -d com.apple.quarantine {} \;
      ;;
  esac
}

# ----------------------------------------------------------------------
# Get the pattern from the desired column in name_file
# ----------------------------------------------------------------------

get_pattern() {
  local code="$1"
  local colnum="$2"
  awk -v c="$code" -v n="$colnum" '$1 == c {print $n}' ${name_file}
}

# ----------------------------------------------------------------------
# Substitute variables in the pattern
# ----------------------------------------------------------------------

substitute_pattern() {
  local pattern="$1"
  local hemi="$2"
  local desc="$3"
  local space="$4"
  pattern="${pattern//\{bname\}/$bname}"
  pattern="${pattern//\{side\}/$hemi}"
  pattern="${pattern//\{space\}/$space}"
  pattern="${pattern//\{desc\}/$desc}"
  pattern="${pattern//\{nii_ext\}/$nii_ext}"
  echo $pattern
}

# ----------------------------------------------------------------------
# surface estimation
# ----------------------------------------------------------------------

surface_estimation() 
{  
  local bname=$1
  local side=$2
  local mri_dir=$3
  local surf_dir=$4
  local estimate_spherereg=$5
  local multi=$6
  local nii_ext=$7

  # Freesurfer templates
  fshemi="${side/left/lh}"
  fshemi="${fshemi/right/rh}"
  Fsavg=${surf_templates_dir}/${fshemi}.central.freesurfer.gii
  Fsavgsphere=${surf_templates_dir}/${fshemi}.sphere.freesurfer.gii

  # BIDS dependent parameters for coding hemispheres and column in Names.tsv
  if [[ $use_bids_naming -eq 1 ]]; then
    name_columns=3  # 3rd column in Names.tsv
    hemi="${side/left/L}"
    hemi="${hemi/right/R}"
  else
    name_columns=2  # 2nd column in Names.tsv
    hemi="${side/left/lh}"
    hemi="${hemi/right/rh}"
  fi

  # Create dynamic variables for filenames
  for code in "PBT_shape" "GMT_shape" "Hemi_volume" "mT1_volume" "PPM_volume" "GMT_volume" "Mid_surface" "Pial_surface" "WM_surface" "Sphere_surface" "Spherereg_surface" "Intensity_Mid" "Intensity_Pial" "Intensity_WM"; do
    pattern=$(get_pattern "$code" "$name_columns")
    value=$(substitute_pattern "$pattern" "$hemi""" "")
    # Use eval to assign the result to a variable named after the code
    eval "${code}=\"\$value\""
  done
    
  # Change number of commands if spherical registration is disabled
  if [ "${estimate_spherereg}" -eq 1 ]; then
    ((end_count=8))
  else
    ((end_count=6))
  fi
  if [[ "${save_pial_white}" -eq 1 || "${thickness_method}" -eq 2 ]]; then
    ((end_count++))
  fi
  if [ "${debug}" -eq 0 ]; then
    verbose=""
  else 
    verbose=" -verbose "
  fi

  # This section of the script checks if a specific hemisphere file exists within a given directory.
  count=0
  if [ -f "${mri_dir}/${Hemi_volume}" ]; then

    # Progress indication
    ((count++))
    if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Calculate $side thickness        "; fi
  
    # Executes the 'CAT_VolThicknessPbt' tool with various options:
    # - ${verbose} toggles verbose output.
    # - '-n-avgs 8' sets the number of averages for distance estimation.
    # - '-min-thickness' sets a minimum thickness threshold.
    # - '-fwhm' sets the FWHM for thickness smoothing.
    ${bin_dir}/CAT_VolThicknessPbt ${verbose} -correct-voxelsize 0 -median-filter ${median_filter} -sharpen ${sharpening} -downsample ${downsample} -n-avgs 8 -fwhm ${thickness_fwhm} ${mri_dir}/${Hemi_volume} ${mri_dir}/${GMT_volume} ${mri_dir}/${PPM_volume}

    # Updates progress to 'Extract $side surface'.
    ((count++))
    if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Extract $side surface             "; fi
  
    # Executes the 'CAT_VolMarchingCubes' tool to generate a surface mesh from volumetric data:
    # - '-median-filter' applies a median filter a specified number of times to reduce artifacts.
    # - '-pre-fwhm' and '-post-fwhm' control pre and post smoothing.
    # - '-thresh' sets the isovalue for mesh generation.
    # - '-no-distopen' disables distance-based opening, a form of morphological operation.
    # - '-local-smoothing' applies additional local smoothing to the mesh.
    ${bin_dir}/CAT_VolMarchingCubes ${verbose} -label ${mri_dir}/${Hemi_volume} -strength-gyrimask 0.1 -median-filter ${median_filter} -pre-fwhm ${pre_fwhm} -iter-laplacian 50 -thresh 0.5 ${mri_dir}/${PPM_volume} ${surf_dir}/${Mid_surface}

    # Reduce surface mesh to smaller size:
    # - '-ratio' defines target triangle ratio in (0,1], e.g., 0.5 keeps ~50% of faces (default 0.25)
    # - '-aggr' defines aggressiveness of simplification (default 7)
    ${bin_dir}/CAT_SurfReduce ${verbose} -aggr 7 -ratio 0.25 ${surf_dir}/${Mid_surface} ${surf_dir}/${Mid_surface}

    # Updates progress to 'Map $side thickness values'.
    ((count++))
    if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Map $side thickness values        "; fi

    # Executes 'CAT_Vol2Surf' to map volumetric data to a surface representation.
    # It uses a weighted average approach for mapping, ranging from -0.4..0.4 of the relative thickness using 5 steps
    ${bin_dir}/CAT_Vol2Surf -weighted-avg -start -0.4 -steps 5 -end 0.4 ${surf_dir}/${Mid_surface} ${mri_dir}/${GMT_volume} ${surf_dir}/${PBT_shape}
    
    # For thickness_method==3 we use the pure PBT-measure
    if [ "${thickness_method}" -eq 3 ]; then
      cp ${surf_dir}/${PBT_shape} ${surf_dir}/${GMT_shape}
    else
      ${bin_dir}/CAT_SurfDistance ${verbose} -check_intersect -max 6.0 -mean -thickness ${surf_dir}/${PBT_shape} ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape}
    fi

    # Updates progress to 'Deform $side surface'
    ((count++))
    if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Refine $side central surface       "; fi

    # Obtain more accurate central surface by surface deformation to PPM image
    ${bin_dir}/CAT_SurfDeform -remove_intersect -isovalue 0.5 -w1 0.1 -w2 0.1 -w3 1.0 -sigma 0.2 ${mri_dir}/${PPM_volume} ${surf_dir}/${Mid_surface} ${surf_dir}/${Mid_surface}    

    # Executes 'CAT_Surf2PialWhite' to estimate both pial and white matter surfaces.
    # - '-w1' sets the internal smoothness weight.
    # - '-w2' sets the gradient alignment weight.
    # - '-w3' sets the balloon force weight.
    # - '-w4' sets the conncetion force weight.
    # - '-sigma' sets the smoothing size for filtering the displacement field.
    # - '-iter' sets the number of iterations.
    # - '-isovalue' sets the isovalue for mesh generation.
    if [[ "${save_pial_white}" -eq 1 || "${thickness_method}" -eq 2 ]]; then
      # Updates progress to 'Deform $side surface'
      ((count++))
      if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Estimate $side pial and white surface     "; fi
      ${bin_dir}/CAT_Surf2PialWhite ${verbose} -w1 0.1 -w2 0.4 -w3 0.3 -w4 0 -sigma 0.2 -iter 50 ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape} ${mri_dir}/${Hemi_volume} ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface}

      # Get central surface by averaging pial and white matter surface
      ${bin_dir}/CAT_SurfAverage -avg ${surf_dir}/${Mid_surface} ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface}    
    fi
          
    # Optionally estimate thickness by using the mean distance (Tfs) between pial and white matter surface and limit to maximum of 6.0
    if [ "${thickness_method}" -eq 2 ]; then
      # Updates progress to 'Refine $side thickness'
      ((count++))
      if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Refine $side thickness            "; fi
      ${bin_dir}/CAT_SurfDistance -max 6.0 -mean ${surf_dir}/${Pial_surface} ${surf_dir}/${WM_surface} ${surf_dir}/${GMT_shape}
    fi
    
    # Correct cortical thickness that is influenced by folding
    if [ "${correct_folding}" -eq 1 ]; then
      ${bin_dir}/CAT_SurfCorrectThicknessFolding -max 6.0 ${surf_dir}/${Mid_surface} ${surf_dir}/${GMT_shape} ${surf_dir}/${GMT_shape}
    fi

    # Map intensity values of bias-corrected image from central, pial, and white surface for debugging
    if [[ "${debug}" -eq 1 && -f "${mri_dir}/${mT1_volume}" ]]; then
      ${bin_dir}/CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${Mid_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_Mid}
      if [ "${save_pial_white}" -eq 1 ]; then
        ${bin_dir}/CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${Pial_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_Pial}
        ${bin_dir}/CAT_Vol2Surf -start 0 -steps 1 -end 0 ${surf_dir}/${WM_surface} ${mri_dir}/${mT1_volume} ${surf_dir}/${Intensity_WM}
      fi
    fi
  
    # If estimate_spherereg is enabled, additional steps for spherical inflation and estimate_spherereg are performed.
    if [ "${estimate_spherereg}" -eq 1 ]; then
      # Updates progress to 'Spherical inflation $side hemisphere'.
      ((count++))
      if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Spherical inflation $side hemisphere  "; fi
      # Inflates the surface to a sphere with additional areal smoothing.
      ${bin_dir}/CAT_Surf2Sphere ${surf_dir}/${Mid_surface} ${surf_dir}/${Sphere_surface} 6
  
      # Updates progress to 'Spherical estimate_spherereg $side hemisphere'.
      ((count++))
      if [[ "$multi" -ne -2 ]]; then progress_bar $count $end_count "Spherical registration $side hemisphere"; fi
      # Warps the surface to align with a standard sphere template, using specific mapping steps and averaging options.
      ${bin_dir}/CAT_SurfWarp ${verbose} -steps 2 -avg -i ${surf_dir}/${Mid_surface} -is ${surf_dir}/${Sphere_surface} -t ${Fsavg} -ts ${Fsavgsphere} -ws ${surf_dir}/${Spherereg_surface}
    fi

    # remove temporary files if not debugging
    if [ "${debug}" -eq 0 ]; then
      rm ${mri_dir}/${GMT_volume} ${mri_dir}/${PPM_volume}
    fi

    return 0

  else
    if [ "${estimate_seg}" -eq 0 ]; then
      echo "${RED}ERROR: Could not find ${mri_dir}/${Hemi_volume}. Please run T1Prep with the '--hemisphere' flag first.${NC}" >&2
    else
      echo "${RED}ERROR: ${python} ${src_dir}/segment.py failed.${NC}" >&2
    fi
    return 1
  fi
}

# ----------------------------------------------------------------------
# get output folder depending on BIDS structure
# ----------------------------------------------------------------------

get_output_folder()
{
  local FILE=$1
  bname=$(basename "$FILE")
  bname="${bname%.nii.gz}"
  bname="${bname%.nii}"

  local dname=$(dirname "$FILE")
  local dname=$(cd "$dname" && pwd) # get absolute path
  
  # check for BIDS folder structure, where the upper folder is "anat"
  local upper_dname=$(basename "$dname") # get upper directory
  if [ "${upper_dname}" == "anat" ]; then
    use_subfolder=0
    subj_folder=$(dirname "$dname")
    subj_folder=$(basename "$subj_folder")
    bids_folder="/derivatives/T1Prep${amap_string}-v${version}/${subj_folder}/anat/"
  else
    use_subfolder=1
    bids_folder=""
  fi
  
  if [ -z "${outdir}" ]; then
    outdir0=${dname}${bids_folder}
  else
    outdir0=${outdir}${bids_folder}
  fi  
} 

# ----------------------------------------------------------------------
# process data
# ----------------------------------------------------------------------

process()
{
  
  errors=0
  SIZE_OF_ARRAY="${#ARRAY[@]}"
  if [[ "$SIZE_OF_ARRAY" -lt 2 && "$multi" -ne -2 ]]; then
    multi=0
  fi
  
  # Call T1Prep script recursively with different "--multi" arguments in case that
  # "--multi" is defined
  if [[ "$multi" -ne 0 && "$multi" -gt -2 ]]; then

    # Filter arguments before recursion
    filtered_args=($(filter_arguments "$@")) # Use an array to handle filtered arguments

    # Call parallelize with filtered arguments and use memory limit per process
    cmd=(
      "${script_dir}/parallelize"
      -l "/tmp"
      -m "${min_memory}"
      -c "$(printf '"%q "' "$0" ${filtered_args[@]} --no-surf --hemisphere --multi -2)"
      "${ARRAY[@]}"
    )
    
    # Execute the command using eval
    if [ "${estimate_seg}" -eq 1 ]; then
      echo "${BOLD}Volume Segmentation${NC}"
      eval "${cmd[@]}"
      status=$?
    fi

    # Call parallelize with filtered arguments
    # Define number of processes, otherwise estimate it automatically 
    if [ "$multi" -gt 0 ]; then
      arg_parallelize="-p ${multi}"
    fi
    cmd=(
      "${script_dir}/parallelize"
      -l "/tmp"
      -p 0.5
      "${arg_parallelize}"
      -c "$(printf '"%q "' "$0" ${filtered_args[@]} --no-seg --multi -2)"
      "${ARRAY[@]}"
    )
    
    # Execute the command using eval
    if [ "${save_surf}" -eq 1 ]; then
      echo "${BOLD}Surface Estimation${NC}"
      eval "${cmd[@]}"
      status=$?
    fi
    
    exit $status
  fi

  # Don't use colored text in parallelization (for clearer log-file)
  if [[ "$multi" -eq -2 ]]; then
    UNDERLINE=""
    BOLD=""
    NC=""
    CYAN=""
    PINK=""
    RED=""
    YELLOW=""
    BLUE=""
    WHITE=""
    GREEN=""
    BLACK=""
  fi
  
  # later add string that indicates use of AMAP
  if [[ "${use_amap}" -eq 1 ]]; then
    amap_string=""
  else
    amap_string="-no-amap"
  fi
  
  i=0
  j=0
  while [ "$i" -lt "$SIZE_OF_ARRAY" ]; do

    # check whether absolute or relative names were given
    if [ ! -f "${ARRAY[$i]}" ]; then
      if [ -f "${pwd}/${ARRAY[$i]}" ]; then
        FILE="${pwd}/${ARRAY[$i]}"
      fi
    else
      FILE="${ARRAY[$i]}"
    fi

    # replace white spaces
    FILE="${FILE// /\\ }"

    # check whether processed files exist if no-overwrite flag is used
    if [ -n "${no_overwrite}" ]; then
      
      get_output_folder $FILE
      
      if [ "${use_bids_naming}" -eq 1 ]; then  
        processed=$(ls "${outdir0}/${bname}"*"/${no_overwrite}"* 2>/dev/null)
      else
        processed=$(ls "${outdir0}/${no_overwrite}${bname}"* 2>/dev/null)
      fi
    fi
    
    if [ -z "${processed}" ]; then
      ARRAY2[$j]="$FILE"
      ((j++))
    else
      echo Skip processing of ${FILE}
    fi
    ((i++))
  done
  
  
  i=0
  SIZE_OF_ARRAY="${#ARRAY2[@]}"
  
  # Exit if no files could be found for processing
  if [ "$SIZE_OF_ARRAY" -eq 0 ]; then
    exit 0
  fi

  # set overall starting time
  start0=$(date +%s)

  # use defined environment
  source ${T1prep_env}/bin/activate

  while [ "$i" -lt "$SIZE_OF_ARRAY" ]; do
    
    # set starting time
    start=$(date +%s)

    FILE="${ARRAY2[$i]}"

    get_output_folder $FILE

    # check again whether processed files exist if no-overwrite flag is used
    if [ -n "${no_overwrite}" ]; then
      if [ "${use_bids_naming}" -eq 1 ]; then  
        processed=$(ls "${outdir0}/${no_overwrite}${bname}"* 2>/dev/null)
      else
        processed=$(ls "${outdir0}/${bname}"*"${no_overwrite}"* 2>/dev/null)
      fi

      # Check if $processed is empty
      if [ -n "$processed" ]; then
        echo Skip processing of ${FILE}
        break  # Skip to the next iteration of the loop
      fi
    fi
    
    # get output folders for surfaces and volumes
    if [[ "${use_bids_naming}" -eq 1 || "${use_subfolder}" -eq 0 ]]; then  
      mri_dir=${outdir0}
      surf_dir=${outdir0}
      report_dir=${outdir0}
      label_dir=${outdir0}
    else
      mri_dir=${outdir0}/mri
      surf_dir=${outdir0}/surf
      report_dir=${outdir0}/report
      label_dir=${outdir0}/label
    fi
              
    # create output folders    
    dir_list="$mri_dir"
    [ "${save_surf}" -eq 1 ] && dir_list+=" $surf_dir"
    dir_list+=" $report_dir"
    dir_list+=" $label_dir"
    mkdir -p $dir_list
        
    # print progress and filename
    j=$(expr $i + 1)
    if [ "${multi}" -ne -2 ]; then
      echo "${BOLD}-------------------------------------------------------${NC}"
      if [ "${SIZE_OF_ARRAY}" -gt 1 ]; then
        echo "${GREEN}${j}/${SIZE_OF_ARRAY} ${BOLD}Processing ${FILE}${NC}"
      else
        echo "${BOLD}Processing ${FILE}${NC}"
      fi
    fi

    input="${FILE}"
    
    # 1. Call deepmriprep segmentation 
    # ----------------------------------------------------------------------
    # check for outputs from previous step
    if [ -f "${input}" ]; then

      # Initialize command string with the Python script call

      cmd="${python} ${src_dir}/segment.py"
      
      # Append options conditionally
      [ "${use_amap}" -eq 1 ] && cmd+=" --amap --amapdir ${bin_dir}"
      [ "${save_mwp}" -eq 1 ] && cmd+=" --mwp"
      [ "${save_wp}" -eq 1 ] && cmd+=" --wp"
      [ "${save_rp}" -eq 1 ] && cmd+=" --rp"
      [ "${save_p}" -eq 1 ] && cmd+=" --p"
      [ "${nii_ext}" == "nii.gz" ] && cmd+=" --gz"
      [ "${save_lesions}" -eq 1 ] && cmd+=" --lesions --amapdir ${bin_dir}"
      [ "${use_bids_naming}" -eq 1 ] && cmd+=" --bids"
      [ "${multi}" -ne -2 ] && cmd+=" --verbose"
      [ "${debug}" -eq 1 ] && cmd+=" --debug"
      [ "${save_surf}" -eq 1 ] || [ "${save_hemi}" -eq 1 ] && cmd+=" --surf"
      [ "${save_csf}" -eq 1 ] && cmd+=" --csf"   
      
      cmd+=" --vessel \"${vessel}\" --label_dir \"${label_dir}\""
      cmd+=" --input \"${input}\" --mri_dir \"${mri_dir}\""
      cmd+=" --report_dir \"${report_dir}\" --atlas \"${atlas}\""
      
      # Execute the command and capture exit code
      if [ "${estimate_seg}" -eq 1 ]; then
        eval "${cmd}"
        seg_status=$?
      else
        seg_status=0
      fi

      if [ "$seg_status" -ne 0 ]; then
        if [[ "$multi" -ne -2 ]]; then
          progress_bar $end_count $end_count "Segmentation failed" "" 1
        fi
        ((i++))
        ((errors++))
        echo "Error in ${input}"
        continue
      fi
  
    else
      echo "${RED}ERROR: ${input} could not be found.${NC}" >&2
      ((i++))
      ((errors++))
      continue
    fi
    
    # optionally extract surface
    if [ "${save_surf}" -eq 1 ]; then
        
      # 2. Estimate thickness and percentage position maps for each hemisphere
      #  and extract cortical surface and call it as background process to
      # allow parallelization
      # ----------------------------------------------------------------------
      # check for outputs from previous step
      pids=()
      for side in left right; do
        surface_estimation $bname $side $mri_dir $surf_dir $estimate_spherereg $multi $nii_ext &
        pids+=("$!")
      done

      surf_status=0
      for pid in "${pids[@]}"; do
        wait "$pid" || surf_status=1
      done

      if [ "$surf_status" -ne 0 ]; then
        if [[ "$multi" -ne -2 ]]; then
          progress_bar $end_count $end_count "Surface estimation failed" "" 1
        fi
        ((errors++))
        echo "Error in ${bname}"
      fi
      
    fi # save_surf

    # print execution time per data set
    end=$(date +%s)
    runtime=$((end - start))
    hours=$(($runtime / 3600))
    min=$((($runtime / 60) % 60))
    s=$(($runtime % 60))
    overall="Finished after "
    if [ $hours -gt 0 ]; then overall+="${hours}hrs "; fi
    if [ $min -gt 0 ]; then overall+="${min}min "; fi
    overall+="${s}s"

    if [[ "$multi" -ne -2 ]]; then
      echo "${GREEN}-------------------------------------------------------                                ${NC}"
      echo "${GREEN}${overall}${NC}"
    fi
      
    ((i++))
  done
  
  # print overall execution time for more than one data set
  if [ "$SIZE_OF_ARRAY" -gt 1 ]; then
    end0=`date +%s`
    runtime=$((end0-start0))
    runtime="T1Prep finished after $(($runtime / 3600))hrs $((($runtime / 60) % 60))min $(($runtime % 60))s"
    echo "${GREEN}${runtime}${NC}"  
  fi
  
  exit $errors

}

# ----------------------------------------------------------------------
# help
# ----------------------------------------------------------------------

help() {
cat << EOM
${BOLD}${BLUE}T1Prep Computational Anatomy Pipeline (PyCAT)
---------------------------------------------${NC}

${BOLD}USAGE:${NC}
  ${GREEN}T1Prep [options] <filename(s)>${NC}

${BOLD}DESCRIPTION:${NC}
T1Prep is a pipeline that preprocesses T1-weighted MRI data and supports segmentation 
and cortical surface reconstruction. It provides a complete set of tools for efficiently 
processing structural MRI scans.

T1Prep partially integrates DeepMriPrep, which uses deep learning (DL) techniques to 
mimic CAT12''s functionality for processing structural MRIs.

As with other DL-based methods, DeepMriPrep slightly underestimates gray matter in 
cases of significant atrophy. Therefore, it is primarily used for bias field correction, 
lesion detection, and as an initial estimate for the subsequent AMAP segmentation from CAT12. 
The skull-stripping and nonlinear spatial registration steps provided by DeepMriPrep are 
unaffected by this bias and are fully utilized in T1Prep.

Cortical surface reconstruction and thickness estimation are performed using Cortex 
Analysis Tools for Surface, a core component of the CAT12 toolbox.

${BOLD}OPTIONS:${NC}
  ${BOLD}${YELLOW}General Options:${NC}
  --defaults <FILE>           Define alternative defaults file.
  --install                   Install the required Python libraries.
  --re-install                Remove the existing installation and reinstall the required Python libraries.
  --python <FILE>             Set the Python interpreter to use (default: $python).
  --multi <NUMBER>            Set the number of processes for parallelization. Use '-1' to automatically 
                              detect the number of available processors (default: $multi).
  --min-memory <NUMBER>       Set the minimum memory size in GB for each process to be parallelized.
                              The default value of $min_memory GB can be increased if your system runs 
                              low on memory and becomes unresponsive during parallelization.. 
                              detect the number of available processors (default: $multi).
  --debug                     Enable verbose output, retain temporary files, and save additional 
                              debugging information.
  
  ${BOLD}${YELLOW}Save Options:${NC}
  --out-dir <DIR>             Set the relative output directory (default: current working directory).
  --no-overwrite <STRING>     Avoid overwriting existing results by checking for the specified 
                              filename pattern.
  --gz                        Save images as nii.gz instead of nii.
  --no-surf                   Skip surface and thickness estimation.
  --no-seg                    Skip segmentation processing.
  --no-sphere-reg             Skip spherical surface registration.
  --no-mwp                    Skip the estimation of modulated and warped segmentations.
  --pial-white                Additionally estimate pial and white matter surface during 
                              surface estimation.
  --hemisphere                Additionally save hemispheric partitions of the segmentation.
  --wp                        Additionally save warped segmentations.
  --rp                        Additionally save affine-registered segmentations.
  --p                         Additionally save native space segmentations.
  --csf                       Additionally save CSF segmentations (default: only GM/WM are saved).
  --lesions                   Additionally save WMH lesions.
  --atlas                     Define an atlas list in the format "'suit','cobra'" (default: $atlas).
  --bids                      Use BIDS (Brain Imaging Data Structure) standard for output file 
                              naming conventions (not yet fully working!).

  ${BOLD}${YELLOW}Expert Options:${NC}
  --no-amap                   Use DeepMRIPrep instead of AMAP for segmentation. Please note 
                              that this might lead to an underestimation of gray matter (GM) 
                              in cases of significant atrophy.
  --thickness-method <NUMBER> Set the thickness method (default: $thickness_method).
                              Use 1 for the Tfs-distance from Freesurfer for PBT-based measure,
                              2 for the Tfs-distance from Freesurfer based on distance between 
                              pial and white matter surfaces, and 3 for the pure PBT-based approach
  --no-correct-folding        Do not correct for cortical thickness by folding effects.
  --pre-fwhm <NUMBER>         Set the pre-smoothing FWHM size in CAT_VolMarchingCubes (default: $pre_fwhm).
  --post-fwhm <NUMBER>        Set the post-smoothing FWHM size in CAT_VolMarchingCubes (default: $post_fwhm).
  --thickness-fwhm <NUMBER>   Set the FWHM size for volumetric thickness smoothing in 
                              CAT_VolThicknessPbt (default: $thickness_fwhm).
  --sharpening <NUMBER>       Set the sharpening amount applied to the PPM map by enhancing differences
                              between the unsmoothed and smoothed PPM maps (default: $sharpening).
  --vessel <NUMBER>           Set the initial white matter (WM) threshold for vessel removal. 
                              Use 0.2 for mild cleanup, 0.5 for strong cleanup, or 0 to disable 
                              vessel removal (default: $vessel).
  --median-filter <NUMBER>    Set the number of median filter applications to reduce topology 
                              artifacts (default: $median_filter).
  
  ${BOLD}${YELLOW}Examples:${NC}

${BLUE}${root_dir}/T1Prep --out-dir test_folder sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Generate segmentation and 
  surface maps, saving the results in the 'test_folder' directory.

${BLUE}${root_dir}/T1Prep --no-surf sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii', but skip surface creation. 
  Only segmentation maps are generated and saved in the same directory as the input files.

${BLUE}${root_dir}/T1Prep --python python3.8 --no-overwrite "surf/lh.thickness." sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii' and use python3.8. Skip processing 
  for files where 'surf/lh.thickness.*' already exists, and save new results in the same 
  directory as the input files.

${BLUE}${root_dir}/T1Prep --lesions --no-sphere-reg sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Skip processing of spherical
  registration, but additionally save lesion map (named p7sTRIO*.nii) in native space.
   
${BLUE}${root_dir}/T1Prep --no-amap sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii' and use DeppMriPrep instead of AMAP
  segmentation.

${BLUE}${root_dir}/T1Prep --multi 8 --p --csf --atlas "'neuromorphometrics', 'suit'" sTRIO*.nii${NC}
  Process all files matching the pattern 'sTRIO*.nii'. Additionally save segmentations 
  in native space, including CSF segmentationand estimate ROI volumes for the defined atlases.
  The processing pipeline involves two stages 
  of parallelization:
  
  1. Segmentation (Python-based): Runs best with at least 12GB of memory per process. 
     The number of processes is automatically estimated based on available memory to 
     optimize resource usage.

  2. Surface Extraction: This stage does not require significant memory and is 
     distributed across all available processors or limited to the defined number.

  If "--multi" is set to a specific number (e.g., 8), the system still estimates memory-based 
  constraints for segmentation parallelization. However, the specified number of processes 
  (e.g., 8) will be used for surface extraction, ensuring efficient parallelization across 
  the two stages. The default setting is -1, which automatically estimates the number of
  available processors.
    
${BOLD}PURPOSE:${NC}
  This script facilitates the analysis of T1-weighted brain images by providing tools for 
  segmentation, surface mapping, and more.

${BOLD}INPUT:${NC}
  Accepts NIfTI files as input.

${BOLD}OUTPUT:${NC}
  Produces segmented images and surface extractions.

${BOLD}USED FUNCTIONS:${NC}
  CAT_VolAmap
  CAT_VolSanlm
  CAT_VolThicknessPbt
  CAT_VolMarchingCubes
  CAT_Vol2Surf
  CAT_SurfAverage
  CAT_Surf2PialWhite
  CAT_SurfDistance
  CAT_SurfWarp
  CAT_Surf2Sphere
  CAT_SurfDeform
  CAT_SurfCorrectThicknessFolding
  CAT_SurfReduce
  ${src_dir}/segment.py
  ${src_dir}/utils.py
  ${script_dir}/progress_bar_multi.sh
  ${script_dir}/progress_bar.sh
  ${script_dir}/parallelize

${BOLD}Author:${NC}
  Christian Gaser (christian.gaser@uni-jena.de)

EOM

check_python
check_python_cmd

# Check whether local Python environment exists
if [ ! -d "${T1prep_env}" ]; then

  # Prompt the user with a Y/N question
  echo "${RED}${BOLD}Local Python environment "${T1prep_env}" not found.${NC}"
  read -p "Do you want to install required Python libraries? (Y/N)" response
  
  # Check if the user's answer is 'Y'
  case "$response" in
    [Yy]*)
      check_python_module venv
      check_python_module pip
      check_python_libraries
      ;;
  esac
fi

}

# ----------------------------------------------------------------------
# call main program
# ----------------------------------------------------------------------

main "${@}"
  